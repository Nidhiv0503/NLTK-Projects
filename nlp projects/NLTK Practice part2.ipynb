{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f73a61",
   "metadata": {},
   "source": [
    "Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1436ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words: ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nidhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Example of single document\n",
    "#Without stopwords\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "string =[\"this is an example of bag of words!\"]\n",
    "\n",
    "vect1 = CountVectorizer()\n",
    "vect1.fit_transform(string)\n",
    "print(\"bag of words:\",vect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d875b955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 5, 'is': 3, 'an': 0, 'example': 2, 'of': 4, 'bag': 1, 'words': 6}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6652eb",
   "metadata": {},
   "source": [
    "Fit and transform and predict if the word is present or not\n",
    "\n",
    "This is widely used for document or subject classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03769bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vect = CountVectorizer()\n",
    "c_vect.fit(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57bc3b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text present at [[0 0 0 2 1 0 1]]\n",
      "original indexes ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
     ]
    }
   ],
   "source": [
    "string2 = ['Lets understand is of words is']\n",
    "c_new_vect = c_vect.transform(string2)\n",
    "print(\"Text present at\",c_new_vect.toarray())\n",
    "\n",
    "#Compare with the indexes\n",
    "print(\"original indexes\",vect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2e461f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
      "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
      "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
      "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
      "                            'itself', ...])\n"
     ]
    }
   ],
   "source": [
    "#Bag of words using stopwords(you can avoid writing extra steps to remove stopwords)\n",
    "\n",
    "stpwords = stopwords.words('english')\n",
    "string = [\"This is an example of bag of words!\"]\n",
    "vect1 = CountVectorizer(stop_words = stpwords)\n",
    "print(vect1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33680153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words: ['bag', 'example', 'words']\n",
      "vocab  : {'example': 1, 'bag': 0, 'words': 2}\n"
     ]
    }
   ],
   "source": [
    "vect1.fit_transform(string)\n",
    "print(\"bag of words:\",vect1.get_feature_names())\n",
    "print(\"vocab  :\",vect1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37d913ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using function\n",
    "def text_matrix(message,countvect):\n",
    "    terms_doc = countvect.fit_transform(message)\n",
    "    return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ed73646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below metrix is the words approach\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>but</th>\n",
       "      <th>for</th>\n",
       "      <th>get</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>langauage</th>\n",
       "      <th>making</th>\n",
       "      <th>mantra</th>\n",
       "      <th>natural</th>\n",
       "      <th>only</th>\n",
       "      <th>practice</th>\n",
       "      <th>processing</th>\n",
       "      <th>progess</th>\n",
       "      <th>slowly</th>\n",
       "      <th>success</th>\n",
       "      <th>the</th>\n",
       "      <th>there</th>\n",
       "      <th>we</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  but  for  get  in  is  langauage  making  mantra  natural  only  \\\n",
       "0    1    0    0    0   1   0          1       1       0        1     0   \n",
       "1    0    0    0    1   0   0          0       0       0        0     0   \n",
       "2    0    1    1    0   0   1          0       0       1        0     1   \n",
       "\n",
       "   practice  processing  progess  slowly  success  the  there  we  will  \n",
       "0         0           1        1       2        0    0      0   1     0  \n",
       "1         0           0        0       0        0    0      1   1     1  \n",
       "2         1           0        0       0        1    1      0   0     0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = [\"We are slowly slowly making progess in natural Langauage processing\",\"we will get there\",\"But practice is the only mantra for success\"]\n",
    "\n",
    "c_vect = CountVectorizer()\n",
    "print('Below metrix is the words approach')\n",
    "text_matrix(message, c_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb198742",
   "metadata": {},
   "source": [
    "n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d4dab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram : ['an', 'example', 'gram', 'is', 'of', 'this']\n",
      "2-gram : ['an example', 'an example of', 'example of', 'example of gram', 'is an', 'is an example', 'of gram', 'this is', 'this is an']\n",
      "3-gram : ['an example of', 'example of gram', 'is an example', 'this is an']\n",
      "4-gram : ['an example of gram', 'is an example of', 'this is an example']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "string = [\"This is an example of gram!\"]\n",
    "\n",
    "vect1 = CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "vect1.fit_transform(string)\n",
    "\n",
    "vect2 = CountVectorizer(ngram_range=(2,3))\n",
    "vect2.fit_transform(string)\n",
    "\n",
    "vect3 = CountVectorizer(ngram_range=(3,3))\n",
    "vect3.fit_transform(string)\n",
    "\n",
    "vect4 = CountVectorizer(ngram_range=(4,4))\n",
    "vect4.fit_transform(string)\n",
    "\n",
    "print(\"1-gram :\",vect1.get_feature_names())\n",
    "\n",
    "print(\"2-gram :\",vect2.get_feature_names())\n",
    "print(\"3-gram :\",vect3.get_feature_names())\n",
    "print(\"4-gram :\",vect4.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8ad77fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>be</th>\n",
       "      <th>can</th>\n",
       "      <th>confusiong</th>\n",
       "      <th>example</th>\n",
       "      <th>how</th>\n",
       "      <th>idf</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>see</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>will</th>\n",
       "      <th>works</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    an   be  can  confusiong  example       how  idf   is        it       see  \\\n",
       "0  0.5  0.0  0.0         0.0      0.5  0.000000  0.0  0.5  0.000000  0.000000   \n",
       "1  0.0  0.0  0.0         0.0      0.0  0.408248  0.0  0.0  0.408248  0.408248   \n",
       "2  0.0  0.5  0.5         0.5      0.0  0.000000  0.5  0.0  0.000000  0.000000   \n",
       "\n",
       "   this        we      will     works  \n",
       "0   0.5  0.000000  0.000000  0.000000  \n",
       "1   0.0  0.408248  0.408248  0.408248  \n",
       "2   0.0  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "tfid = TfidfVectorizer(smooth_idf=False)\n",
    "doc = [\"This is an example.\",\"we will see how it works.\",\"IdF can be confusiong\"]\n",
    "doc_vector = tfid.fit_transform(doc)\n",
    "#print(tfid.get_feature_names())\n",
    "\n",
    "df = pd.DataFrame(doc_vector.todense(),columns=tfid.get_feature_names())\n",
    "df\n",
    "#print(doc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f00294d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using function\n",
    "def text_matrix(message,countvect):\n",
    "    terms_doc = countvect.fit_transform(message)\n",
    "    return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "460d829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>cases</th>\n",
       "      <th>covid</th>\n",
       "      <th>dropping</th>\n",
       "      <th>is</th>\n",
       "      <th>nothing</th>\n",
       "      <th>that</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.501651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.322745</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        are     cases     covid  dropping        is   nothing      that  \\\n",
       "0  0.000000  0.000000  0.592567  0.000000  0.381519  0.000000  0.501651   \n",
       "1  0.000000  0.000000  0.425441  0.000000  0.547832  0.720333  0.000000   \n",
       "2  0.546454  0.546454  0.322745  0.546454  0.000000  0.000000  0.000000   \n",
       "\n",
       "       what  \n",
       "0  0.501651  \n",
       "1  0.000000  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will cal the function created earlier\n",
    "feb_message = [\"What is that covid covid\",\n",
    "              \"covid is nothing\",\n",
    "              \"covid cases are dropping\"]\n",
    "tf = TfidfVectorizer()\n",
    "#passing same message with TF-IDF\n",
    "text_matrix(feb_message,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0db62942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>covid</th>\n",
       "      <th>is</th>\n",
       "      <th>tht</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668501</td>\n",
       "      <td>0.334251</td>\n",
       "      <td>0.469778</td>\n",
       "      <td>0.469778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.704909</td>\n",
       "      <td>0.501549</td>\n",
       "      <td>0.501549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bad     covid        is       tht      what\n",
       "0  0.000000  0.668501  0.334251  0.469778  0.469778\n",
       "1  0.704909  0.501549  0.501549  0.000000  0.000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing of Covid incresed based on the occurance and total document\n",
    "jul_message = [\"What is tht covid covid\",\n",
    "              \"covid is bad\"]\n",
    "text_matrix(jul_message,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b06dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "arr = [\"Car was cleaned by Jack\",\n",
    "      \"Jack was cleaned by car.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23810c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Name \n",
      " ['by car', 'by jack', 'car was', 'cleaned by', 'jack was', 'was cleaned']\n",
      "Array \n",
      " [[0 1 1 1 0 1]\n",
      " [1 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#If you want to take into account just term frequencies:\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "#The ngram range specifies your ngram cofiguration\n",
    "\n",
    "x = vectorizer.fit_transform(arr)\n",
    "#testing the ngram generation:\n",
    "print(\"Feature Name \\n\",vectorizer.get_feature_names())\n",
    "print('Array \\n',x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb68c59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.57615236 0.57615236 0.40993715 0.         0.40993715]\n",
      " [0.57615236 0.         0.         0.40993715 0.57615236 0.40993715]]\n"
     ]
    }
   ],
   "source": [
    "#and now testing TFIDF vectorizer:\n",
    "#You can still specify n-gram here\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "x = vectorizer.fit_transform(arr)\n",
    "\n",
    "#Testing the TFIDF value +ngrams:\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d351626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.40546511 1.40546511 1.         0.         1.        ]\n",
      " [1.40546511 0.         0.         1.         1.40546511 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Testing TFIDF vectorizer without normalization:\n",
    "#you can still specify n-gram here\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2),norm=None)\n",
    "\n",
    "x = vectorizer.fit_transform(arr)\n",
    "\n",
    "#Testing TFIDF value before normalization:\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b37ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
